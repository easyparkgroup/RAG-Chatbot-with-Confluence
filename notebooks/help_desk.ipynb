{
 "cells": [
  {
   "cell_type": "code",
   "id": "e9e103bc-1f9b-4348-bf17-09d2d32fed07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.738286Z",
     "start_time": "2024-12-20T20:13:02.130920Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "53539806-a791-4264-8cab-b72883e29c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.738452Z",
     "start_time": "2024-12-20T20:13:02.142610Z"
    }
   },
   "source": [
    "# Env variable\n",
    "sys.path.append(\"../\")\n",
    "load_dotenv(find_dotenv())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "33438b7e-e989-412e-87e3-e12eb7401846",
   "metadata": {},
   "source": [
    "# 1. Confluence Loader "
   ]
  },
  {
   "cell_type": "code",
   "id": "ed22f7b3-5e5e-41fe-a583-e6393609e716",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.738615Z",
     "start_time": "2024-12-20T20:13:02.166303Z"
    }
   },
   "source": [
    "username = os.getenv(\"CONFLUENCE_USERNAME\")\n",
    "api_token = os.getenv(\"CONFLUENCE_API_KEY\")\n",
    "base_url = os.getenv(\"CONFLUENCE_BASE_URL\")\n",
    "space_key = os.getenv(\"CONFLUENCE_SPACE_KEY\")\n"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "dc19ab73-5f9d-4f0d-a80d-c49d502d9fc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.738722Z",
     "start_time": "2024-12-20T20:13:02.198417Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import ConfluenceLoader\n",
    "\n",
    "loader = ConfluenceLoader(\n",
    "    url=base_url,\n",
    "    username=username,\n",
    "    api_key=api_token,\n",
    "    space_key=space_key,\n",
    "    limit=10,\n",
    "    # include_attachments=True, # uncomment to include png, jpeg, ..\n",
    "    max_pages=50,\n",
    "    keep_markdown_format=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "103b9b37-255f-4b76-ad4e-8e8af459b027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:08.924583Z",
     "start_time": "2024-12-20T20:13:02.211652Z"
    }
   },
   "source": "docs = loader.load()",
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "3c7028f0-6923-40bd-bddd-6bcb94302540",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:08.941467Z",
     "start_time": "2024-12-20T20:13:08.939046Z"
    }
   },
   "source": [
    "# Look at one page content and its metadata\n",
    "print(\"Content: \\n ------- \\n\" + docs[-1].page_content)\n",
    "print(\"Metadatas: \\n ------- \\n\" + str(docs[-1].metadata))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \n",
      " ------- \n",
      "\n",
      "\n",
      "The Basingstoke Maplewood office has a number of options for team meals but these may not be immediately obvious.\n",
      "\n",
      "1. **Pizza from Pizzeria Gali**  \n",
      "   <https://pizzeriagali.co.uk/>  \n",
      "   [info@pizzeriagali.co.uk](mailto:info@pizzeriagali.co.uk)  \n",
      "   Open: 12 - 2pm. Closed Mondays.  \n",
      "   This is freshly cooked Pizza with quality ingredients. We’ve ordered food for 30 people from here and he’s more than happy to accommodate. Give him some advance notice but normally payment is on the day via credit card. He’s located next to Fitness First on the business park. He will deliver but it’s so close pickup might be easier. Large order was around £400. For small teams there’s also the option to drop into their restaurant which is about a ten minute walk.\n",
      "2. **Mannicitas Food**  \n",
      "   <https://mannicitas.com/our-menu/>   \n",
      "   This is a local lady who caters for businesses. Minimum order size would be about 10 people. We’ve sampled her food and it was excellent. Website doesn’t do the food justice. She seemed very flexible and able to cater any sort of requests.\n",
      "3. **Will’s meals**  \n",
      "   <https://www.wills-meals.co.uk/>   \n",
      "   Will lives locally and can supply large orders. The website isn’t very helpful but he’s supplied for our group several times. It’s a bit of a strange system but you basically phone him up and tell him how many people and he drops it off on the day. Our standard order is chips, coleslaw, chicken nuggets and curry. This always goes down well with the team. Last invoice was around £600.\n",
      "4. **M&S**   \n",
      "   <https://www.marksandspencer.com/l/food-to-order/sandwich-platters>   \n",
      "   M&S is in the Chineham Shopping Center. They require a few days notice but large platters can be assembled and collected.\n",
      "\n",
      "Metadatas: \n",
      " ------- \n",
      "{'title': 'Places for team lunch around Maplewood', 'id': '4714168344', 'source': 'https://easypark.jira.com/wiki/spaces/EP/pages/4714168344/Places+for+team+lunch+around+Maplewood', 'when': '2024-08-19T15:54:43.947Z'}\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "9ded8289-b075-4ac8-aee9-b5a06230e4a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:08.962028Z",
     "start_time": "2024-12-20T20:13:08.959748Z"
    }
   },
   "source": [
    "def pretty_print(chunks):\n",
    "    print(\n",
    "        str(\"\\n\" + \"=\" * 50 + \"\\n\").join(\n",
    "            [chunk.page_content + \"\\n\" + \"-\" * 50 + \"\\n\" + str(chunk.metadata) for chunk in chunks]\n",
    "        )\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "id": "954f5814-648b-46c4-9868-180c66bc7ee8",
   "metadata": {},
   "source": [
    "## 2. Document Splitter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19407e7-5052-497d-b804-4c9e496303f5",
   "metadata": {},
   "source": [
    "### Document Example"
   ]
  },
  {
   "cell_type": "code",
   "id": "f796d3d7-fd19-4939-8988-cb79b9dcaa34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:08.988938Z",
     "start_time": "2024-12-20T20:13:08.984958Z"
    }
   },
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "# I am a title\n",
    "## I am a subtitle\n",
    "\n",
    "I am a block of text. However, my size is quite long. I would first like the MarkdownHeaderTextSplitter\n",
    "to identify my title and subtitle in its metadata.\n",
    "\n",
    "I then want RecursiveCharacterTextSplitter to identify the two parts that compose me\n",
    "because my size would be too large to feed a language model.\n",
    "\n",
    "Finally, I would like the metadata corresponding to my origins, namely the url, to be merged with my title and subtitle\n",
    "information.\n",
    "\"\"\"\n",
    "\n",
    "metadata = {\"url\": \"https://my_origin.com\"}\n",
    "\n",
    "sample = Document(page_content=text, metadata=metadata)"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "id": "d850685e-1ab8-4bfc-a3ba-51dc10c3ceff",
   "metadata": {},
   "source": [
    "### MarkdownHeaderTextSplitter example"
   ]
  },
  {
   "cell_type": "code",
   "id": "04e97186-9770-4306-a7a3-b6c27e355af9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.007722Z",
     "start_time": "2024-12-20T20:13:09.005302Z"
    }
   },
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "# Markdown\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Heading 1\"),\n",
    "    (\"##\", \"Heading 2\"),\n",
    "    (\"###\", \"Heading 3\"),\n",
    "]\n",
    "\n",
    "# Markdown splitter\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "chunks = markdown_splitter.split_text(sample.page_content)\n",
    "\n",
    "print(chunks)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Heading 1': 'I am a title', 'Heading 2': 'I am a subtitle'}, page_content='I am a block of text. However, my size is quite long. I would first like the MarkdownHeaderTextSplitter\\nto identify my title and subtitle in its metadata.  \\nI then want RecursiveCharacterTextSplitter to identify the two parts that compose me\\nbecause my size would be too large to feed a language model.  \\nFinally, I would like the metadata corresponding to my origins, namely the url, to be merged with my title and subtitle\\ninformation.')]\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "id": "1073d0b9-807f-4768-8e07-674b14474cb6",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter example"
   ]
  },
  {
   "cell_type": "code",
   "id": "50ac8082-4847-4d8d-87f3-784950c5a03c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.027173Z",
     "start_time": "2024-12-20T20:13:09.024682Z"
    }
   },
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=20,\n",
    "    separators=[\"#\", r\"\\n\\n\", r\"\\n\", r\"(?<=\\. )\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "splitted_chunks = splitter.split_documents(chunks)\n",
    "\n",
    "pretty_print(splitted_chunks)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a block of text. However, my size is quite long. I would first like the MarkdownHeaderTextSplitter\n",
      "to identify my title and subtitle in its metadata.  \n",
      "I then want RecursiveCharacterTextSplitter to identify the two parts that compose me\n",
      "because my\n",
      "--------------------------------------------------\n",
      "{'Heading 1': 'I am a title', 'Heading 2': 'I am a subtitle'}\n",
      "==================================================\n",
      "me\n",
      "because my size would be too large to feed a language model.  \n",
      "Finally, I would like the metadata corresponding to my origins, namely the url, to be merged with my title and subtitle\n",
      "information.\n",
      "--------------------------------------------------\n",
      "{'Heading 1': 'I am a title', 'Heading 2': 'I am a subtitle'}\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "id": "7e305dc2-cc44-4946-ac32-3da1366f802c",
   "metadata": {},
   "source": [
    "### MarkdownHeaderTextSplitter & RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "id": "7993fabc-5213-4e2e-b280-e8eaadfc11b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.051453Z",
     "start_time": "2024-12-20T20:13:09.045311Z"
    }
   },
   "source": [
    "# Markdown\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Heading 1\"),\n",
    "    (\"##\", \"Heading 2\"),\n",
    "    (\"###\", \"Heading 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Split based on markdown and add original metadata\n",
    "md_docs = []\n",
    "for doc in [sample]:\n",
    "    md_doc = markdown_splitter.split_text(doc.page_content)\n",
    "    for i in range(len(md_doc)):\n",
    "        md_doc[i].metadata = md_doc[i].metadata | doc.metadata\n",
    "    md_docs.extend(md_doc)\n",
    "\n",
    "# RecursiveTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Chunk size big enough\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256, chunk_overlap=20, separators=[\"\\n\\n\", \"\\n\", r\"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "splitted_docs = splitter.split_documents(md_docs)\n",
    "\n",
    "pretty_print(splitted_docs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a block of text. However, my size is quite long. I would first like the MarkdownHeaderTextSplitter\n",
      "to identify my title and subtitle in its metadata.  \n",
      "I then want RecursiveCharacterTextSplitter to identify the two parts that compose me\n",
      "--------------------------------------------------\n",
      "{'Heading 1': 'I am a title', 'Heading 2': 'I am a subtitle', 'url': 'https://my_origin.com'}\n",
      "==================================================\n",
      "because my size would be too large to feed a language model.  \n",
      "Finally, I would like the metadata corresponding to my origins, namely the url, to be merged with my title and subtitle\n",
      "information.\n",
      "--------------------------------------------------\n",
      "{'Heading 1': 'I am a title', 'Heading 2': 'I am a subtitle', 'url': 'https://my_origin.com'}\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "3b05a633-b710-4570-8e2c-3893c2b38d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.073449Z",
     "start_time": "2024-12-20T20:13:09.070913Z"
    }
   },
   "source": [
    "def my_custom_splitter(docs):\n",
    "    # Markdown\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Heading 1\"),\n",
    "        (\"##\", \"Heading 2\"),\n",
    "        (\"###\", \"Heading 3\"),\n",
    "    ]\n",
    "\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    # Split based on markdown and add original metadata\n",
    "    md_docs = []\n",
    "    for doc in docs:\n",
    "        md_doc = markdown_splitter.split_text(doc.page_content)\n",
    "        for i in range(len(md_doc)):\n",
    "            md_doc[i].metadata = md_doc[i].metadata | doc.metadata\n",
    "        md_docs.extend(md_doc)\n",
    "\n",
    "    # RecursiveTextSplitter\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "    # Chunk size big enough\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=20, separators=[\"\\n\\n\", \"\\n\", r\"(?<=\\. )\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    splitted_docs = splitter.split_documents(md_docs)\n",
    "    return splitted_docs"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "02123f84-574b-4728-bd35-5a2f0fc45afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.098996Z",
     "start_time": "2024-12-20T20:13:09.087705Z"
    }
   },
   "source": [
    "chunks = my_custom_splitter(docs)"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "id": "b39139f8-23d5-4dbf-86b5-af683a4affb0",
   "metadata": {},
   "source": [
    "# 3. Embeddings & Vector DB "
   ]
  },
  {
   "cell_type": "code",
   "id": "89d8c144-8cfe-4d15-a2da-12518c89dfde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.102585Z",
     "start_time": "2024-12-20T20:13:09.101080Z"
    }
   },
   "source": [
    "persist_directory = \"./db/chroma\""
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "5f9d581f-308b-4998-abce-05ee7943df45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.142391Z",
     "start_time": "2024-12-20T20:13:09.107811Z"
    }
   },
   "source": [
    "# Embeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "75d3eec1-b43a-4619-a4fd-eb0c442fd36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:09.152308Z",
     "start_time": "2024-12-20T20:13:09.148062Z"
    }
   },
   "source": [
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(persist_directory)\n",
    "except FileNotFoundError:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "094d662a-736e-4a5b-bf52-0329d78b9a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.703465Z",
     "start_time": "2024-12-20T20:13:09.163524Z"
    }
   },
   "source": [
    "# Save db\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory)\n",
    "db.persist()"
   ],
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[73], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Save db\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvectorstores\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Chroma\n\u001B[0;32m----> 4\u001B[0m db \u001B[38;5;241m=\u001B[39m \u001B[43mChroma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpersist_directory\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m db\u001B[38;5;241m.\u001B[39mpersist()\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:887\u001B[0m, in \u001B[0;36mChroma.from_documents\u001B[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[1;32m    885\u001B[0m texts \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mpage_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m    886\u001B[0m metadatas \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m--> 887\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpersist_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_settings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    898\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:843\u001B[0m, in \u001B[0;36mChroma.from_texts\u001B[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[1;32m    835\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mchromadb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatch_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_batches\n\u001B[1;32m    837\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m create_batches(\n\u001B[1;32m    838\u001B[0m         api\u001B[38;5;241m=\u001B[39mchroma_collection\u001B[38;5;241m.\u001B[39m_client,  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[1;32m    839\u001B[0m         ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[1;32m    840\u001B[0m         metadatas\u001B[38;5;241m=\u001B[39mmetadatas,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    841\u001B[0m         documents\u001B[38;5;241m=\u001B[39mtexts,\n\u001B[1;32m    842\u001B[0m     ):\n\u001B[0;32m--> 843\u001B[0m         \u001B[43mchroma_collection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    846\u001B[0m \u001B[43m            \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    849\u001B[0m     chroma_collection\u001B[38;5;241m.\u001B[39madd_texts(texts\u001B[38;5;241m=\u001B[39mtexts, metadatas\u001B[38;5;241m=\u001B[39mmetadatas, ids\u001B[38;5;241m=\u001B[39mids)\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:299\u001B[0m, in \u001B[0;36mChroma.add_texts\u001B[0;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    297\u001B[0m ids_with_metadata \u001B[38;5;241m=\u001B[39m [ids[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m non_empty_ids]\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 299\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_collection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupsert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    301\u001B[0m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membeddings_with_metadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts_with_metadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids_with_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected metadata value to be\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/chromadb/api/models/Collection.py:343\u001B[0m, in \u001B[0;36mCollection.upsert\u001B[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[0m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001B[39;00m\n\u001B[1;32m    324\u001B[0m \n\u001B[1;32m    325\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;124;03m    None\u001B[39;00m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    334\u001B[0m upsert_request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_and_prepare_upsert_request(\n\u001B[1;32m    335\u001B[0m     ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[1;32m    336\u001B[0m     embeddings\u001B[38;5;241m=\u001B[39membeddings,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    340\u001B[0m     uris\u001B[38;5;241m=\u001B[39muris,\n\u001B[1;32m    341\u001B[0m )\n\u001B[0;32m--> 343\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_upsert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupsert_request\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mids\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupsert_request\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43membeddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupsert_request\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadatas\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupsert_request\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdocuments\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43muris\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupsert_request\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muris\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m tracer, granularity\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trace_granularity \u001B[38;5;241m<\u001B[39m granularity:\n\u001B[0;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracer:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/chromadb/api/segment.py:103\u001B[0m, in \u001B[0;36mrate_limit.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rate_limit_enforcer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrate_limit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py:23\u001B[0m, in \u001B[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m---> 23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/chromadb/api/segment.py:548\u001B[0m, in \u001B[0;36mSegmentAPI._upsert\u001B[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris, tenant, database)\u001B[0m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_embedding_record_set(coll, records_to_submit)\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_quota_enforcer\u001B[38;5;241m.\u001B[39menforce(\n\u001B[1;32m    539\u001B[0m     action\u001B[38;5;241m=\u001B[39mAction\u001B[38;5;241m.\u001B[39mUPSERT,\n\u001B[1;32m    540\u001B[0m     tenant\u001B[38;5;241m=\u001B[39mtenant,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    545\u001B[0m     uris\u001B[38;5;241m=\u001B[39muris,\n\u001B[1;32m    546\u001B[0m )\n\u001B[0;32m--> 548\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_producer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcollection_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecords_to_submit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m tracer, granularity\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m trace_granularity \u001B[38;5;241m<\u001B[39m granularity:\n\u001B[0;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracer:\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Developer/EasyPark/FRH/RAG-Chatbot-with-Confluence/.venv/lib/python3.12/site-packages/chromadb/db/mixins/embeddings_queue.py:243\u001B[0m, in \u001B[0;36mSqlEmbeddingsQueue.submit_embeddings\u001B[0;34m(self, collection_id, embeddings)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# The returning clause does not guarantee order, so we need to do reorder\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;66;03m# the results. https://www.sqlite.org/lang_returning.html\u001B[39;00m\n\u001B[1;32m    242\u001B[0m sql \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msql\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m RETURNING seq_id, id\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# Pypika doesn't support RETURNING\u001B[39;00m\n\u001B[0;32m--> 243\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mfetchall()\n\u001B[1;32m    244\u001B[0m \u001B[38;5;66;03m# Reorder the results\u001B[39;00m\n\u001B[1;32m    245\u001B[0m seq_ids \u001B[38;5;241m=\u001B[39m [cast(SeqId, \u001B[38;5;28;01mNone\u001B[39;00m)] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(\n\u001B[1;32m    246\u001B[0m     results\n\u001B[1;32m    247\u001B[0m )  \u001B[38;5;66;03m# Lie to mypy: https://stackoverflow.com/questions/76694215/python-type-casting-when-preallocating-list\u001B[39;00m\n",
      "\u001B[0;31mOperationalError\u001B[0m: attempt to write a readonly database"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "ee003705-82a0-4663-ad4f-68a0c27e0f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.714233Z",
     "start_time": "2024-12-20T20:11:15.898603Z"
    }
   },
   "source": [
    "# Count the number of chunks in the vector store\n",
    "db._collection.count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "a3c6ed5a-6564-43f9-8c43-df1c7587cdd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.717730Z",
     "start_time": "2024-12-20T20:11:19.018973Z"
    }
   },
   "source": [
    "# db.get()\n",
    "retriever = db.as_retriever()\n",
    "# retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 5, \"score_threshold\": 0.3})"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "c87308ae-214d-4d74-acb8-c1d36078c9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.723015Z",
     "start_time": "2024-12-20T20:11:20.710760Z"
    }
   },
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Given this text extracts:\n",
    "    -----\n",
    "    {context}\n",
    "    -----\n",
    "    Please answer with to the following question:\n",
    "    Question: {question}\n",
    "    Answer: \n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "f4460250-19cd-4bbe-9c6a-12007f60273d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.723490Z",
     "start_time": "2024-12-20T20:11:37.461280Z"
    }
   },
   "source": [
    "# LLM\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(streaming=True)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "729e0c47-4f3b-4312-900d-46ee492e856f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.725509Z",
     "start_time": "2024-12-20T20:11:39.582054Z"
    }
   },
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # or\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "f60d7e1a-70ab-49ff-a127-7269e7ddc4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.733388Z",
     "start_time": "2024-12-20T20:11:58.085869Z"
    }
   },
   "source": [
    "question = \"Best Pizza place near the Basingstoke office?\"\n",
    "\n",
    "query = {\"query\": question}\n",
    "answer = qa(query)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/fpxfvvvd5_51yg965r3twpdw0000gq/T/ipykernel_36458/3193730182.py:4: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "ad2b5066-f323-437c-bf2f-86c6e65c715d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.734727Z",
     "start_time": "2024-12-20T20:12:12.704814Z"
    }
   },
   "source": [
    "from IPython.display import display_markdown\n",
    "\n",
    "display_markdown(answer[\"result\"], raw=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/markdown": " Pizzeria Gali, located next to Fitness First on the business park, offers freshly cooked Pizza with quality ingredients. They can accommodate large orders with advance notice and accept credit card payment on the day. For smaller teams, there is also the option to dine in at their restaurant, which is about a ten minute walk from the office. "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "id": "b3684090-1e06-4281-a3f8-a629989701a3",
   "metadata": {},
   "source": [
    "### Display documents used by the LLM for answering"
   ]
  },
  {
   "cell_type": "code",
   "id": "f813848c-a6dd-44ca-a1e2-c37a3463e54d",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T20:13:11.737024Z",
     "start_time": "2024-12-20T20:12:50.475395Z"
    }
   },
   "source": "retriever.get_relevant_documents(\"Best Pizza place near the Basingstoke office?\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': '4714168344', 'source': 'https://easypark.jira.com/wiki/spaces/EP/pages/4714168344/Places+for+team+lunch+around+Maplewood', 'title': 'Places for team lunch around Maplewood', 'when': '2024-08-19T15:54:43.947Z'}, page_content='The Basingstoke Maplewood office has a number of options for team meals but these may not be immediately obvious.  \\n1. **Pizza from Pizzeria Gali**\\n<https://pizzeriagali.co.uk/>\\n[info@pizzeriagali.co.uk](mailto:info@pizzeriagali.co.uk)\\nOpen: 12 - 2pm. Closed Mondays.'),\n",
       " Document(metadata={'id': '4714168344', 'source': 'https://easypark.jira.com/wiki/spaces/EP/pages/4714168344/Places+for+team+lunch+around+Maplewood', 'title': 'Places for team lunch around Maplewood', 'when': '2024-08-19T15:54:43.947Z'}, page_content='This is freshly cooked Pizza with quality ingredients. We’ve ordered food for 30 people from here and he’s more than happy to accommodate. Give him some advance notice but normally payment is on the day via credit card. He’s located next to Fitness First on the business park. He will deliver but it’s so close pickup might be easier. Large order was around £400. For small teams there’s also the option to drop into their restaurant which is about a ten minute walk.\\n2. **Mannicitas Food**'),\n",
       " Document(metadata={'id': '3923148993', 'source': 'https://easypark.jira.com/wiki/spaces/EP/pages/3923148993/UK+-+Basingstoke', 'title': 'UK - Basingstoke', 'when': '2024-11-20T09:24:14.146Z'}, page_content='**Office Address**  \\nRingGo Limited, Maplewood, Chineham Business Park, Crockford Lane, Basingstoke, Hampshire, RG24 8NE  \\n**Office Access**\\n**Taxis:** 01256 444444 or 01256 242428 (or the hotel can help)'),\n",
       " Document(metadata={'id': '3923148993', 'source': 'https://easypark.jira.com/wiki/spaces/EP/pages/3923148993/UK+-+Basingstoke', 'title': 'UK - Basingstoke', 'when': '2024-11-20T09:24:14.146Z'}, page_content='**Nearby Lunch/Dinner Recommendations (close to the office)**  \\nLunch: The Exchange in the cafe opposite or Deliveroo are the best options.  \\nDinner in the town centre: The Olive House, Lime Leaf, Chennai Express.  \\nOutside of the town centre (pubs/nicer restaurants): The Palm Brasserie, The Falcon, The Game Keepers.  \\n**Getting here from Heathrow Airport**  \\n* **Taxi** - (about 50 minutes) most expensive, worst for our green credentials but by far the easiest')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f76bc-6df7-4184-8044-1f509f625fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
